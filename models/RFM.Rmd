---
title: "RF"
author: "David Oloyede"
date: "4/29/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, message = FALSE, warning=FALSE, echo = FALSE}
library(tidyverse)
base_stroke<- read.csv("../stroke-data.csv", na.strings="N/A", stringsAsFactors = TRUE)

base_stroke = na.omit(base_stroke); base_stroke = base_stroke[-1]
base_stroke$stroke<-as_factor(base_stroke$stroke)
base_stroke$bmi<-as.numeric(base_stroke$bmi)
levels(base_stroke$stroke)<-c("No stroke","Had stroke")
```

Since it is a classification task and we are predicting the response for stroke, we are using random forests. An advantage of random forests is that it allows for a reduction in variance, and thus lower test error, compared to both single decision trees and tree bagging as well as handling categorical, continuous, and non-linear parameters efficiently without need for scaling. First we must split data. The data is split into training set and testing set with an 80-20 split.

```{r, message = FALSE, warning=FALSE}
library(caTools)
set.seed(10)
div<-sample.split(Y = base_stroke$stroke,SplitRatio = 0.80)
base_training<-subset(base_stroke,subset = div == TRUE)
base_test<-subset(base_stroke,subset = div == FALSE)
```

For the random forest model, we'll use `stroke` as our response variable and all other variables (excluding for `id`) as our predictors. This is the formula we will use for the model:
  
\begin{align*}
& \hat{stroke} \sim gender + age + hypertension + heart\_disease + ever\_married + \\
& work\_type + Residence\_type + avg\_glucose\_level + bmi + smoking\_status
\end{align*}

A longer training period and greater complexity in interpretation as a result of multiple trees is the cost of having all the advantages of the model explained previously. This model will consist of 20 trees. 
```{r, message = FALSE, warning=FALSE, out.width = "75%", fig.align='center'}
library(randomForest)
set.seed(1)
(model_RF<-randomForest(formula = stroke ~.,data = base_training,ntree =20))
varImpPlot(model_RF)
```
Our model has and error rate estimate of $4.99\%$ and it looks like the most important models here are `avg_glucose_level, bmi, and age`, which is much different from the important variables from the training models earlier. 


```{r}
prediction<-predict(model_RF,newdata = base_test[,-12])

(confusionMatrix<-table(base_test$stroke,prediction))
(accuracy.rate<-(confusionMatrix[1] + confusionMatrix[4])/ sum(confusionMatrix))
```
With an accuracy rate of $95.5\%$ we can see that the model is not very good however of predicting risk of having a stroke with a bias of not having a stroke. Even though random forests model are not as computationally expensive as a lot of others and can reduce high variance. Let's try splitting the data again ten times to retrieve the mean of the test error rates.

```{r, echo = FALSE}
test.errors = NA

for(i in 1:10) {
  div<-sample.split(Y = base_stroke$stroke,SplitRatio = 0.80)
  base_training<-subset(base_stroke,subset = div == TRUE)
  base_test<-subset(base_stroke,subset = div == FALSE)
  model_RF<-randomForest(formula = stroke ~.,data = base_training,ntree =20)
  
  prediction<-predict(model_RF,newdata = base_test[,-12])
  confusionMatrix<-table(base_test$stroke,prediction)
  
  test.errors[i] = (confusionMatrix[2] + confusionMatrix[3])/sum(confusionMatrix)
}
```

```{r}
test.errors
mean(test.errors)
```

With a test error rate average of $4.43\%$ and conversely an average accuracy rate of $95.57\%$, our random forest model performs poorly with the heavy imbalance of the `stroke` classification. To properly analyze this data, we do in fact have to consider oversampling or undersampling the data.





